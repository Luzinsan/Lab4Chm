# Ход выполнения лабораторной работы

  В ходе данной лабораторной работы был реализован класс NonlinearEquations, в котором содержатся основные методы Ньютона Newton() и наискорейшего спуска SteepestDescent(). 

   В процессе реализации метода Ньютона было выяснено, что в некоторый момент вычисления матрицы Якоби, могут возникать неопределённые значение, в связи с чем было добавлено условие, что если такой случай имел место быть, то матрица Якоби остаётся от предыдущей итерации. Таким образом это явилось неким аналогом метода итераций, в связи с чем сам метод итераций явно реализован не был. 


Метод Ньютона начинается с получения матрицы Якоби. В случае её успешного вычисления, рассчитывается следующее приближенное решение системы по формуле (2.4). Для того чтобы использовать эту формулу, вызываются функции получения обратной матрицы (методом Гаусса)  getInverseMatrixByMethod() и  получения вектор-столбца значений системы функций при заданных аргументах getFunctionValues(). Итерационный процесс прекращается, как только модуль разницы текущего и предыдущего приближения станет меньше, чем требуемая погрешность, либо когда максимальное количество итераций было превышено.


Метод Наискорейшего спуска похож по реализации с методом Итераций (Ньютона). После вычисления матрицы Якоби, если всё прошло успешно, вычисляется вектор-столбца значений системы функций при заданных аргументах, так как он нам понадобится ещё неоднократно. В момент получения следующего приближения используется формула (2.7), где требуется найти параметр минимизации шага спуска 'lambda'  (метод getMinimizingValue()) и вектор-столбец направления градиента.  Для нахождения направления градиента используются уже известные данные в формуле (2.9).  В методе получения параметра минимизации определяются переменные транспонированной матрицы Якоби, вектора градиента и транспонированного вектора градиента. А далее по формуле 2.12 получается нужный параметр.  Итерационный процесс прекращается, как только модуль разницы текущего и предыдущего приближения станет меньше, чем требуемая погрешность, либо когда максимальное количество итераций было превышено
